
// exclusiveScan.cu_inl

// This is a shared-memory implementation of exclusive scan. Note that the
// exclusive scan you implemented in Part 1 uses slower *global* memory, and has
// overhead from performing multiple kernel launches.
// Because it uses shared memory, it must be run within a single thread block.


// REQUIREMENTS:
//  - Input array must have power-of-two length.
//  - Number of threads in the thread block must be the size of the array!
//  - SCAN_BLOCK_DIM is both the number of threads in the block (must be power of 2) 
//         and the number of elements that will be scanned. 
//          You should define this in your cudaRenderer.cu file, 
//          based on your implementation.
//  - The parameter sScratch should be a pointer to an array with 2*SCAN_BLOCK_DIM elements
//  - The 3 arrays should be in shared memory. 

// ================= USAGE (in cudaRenderer.cu) =====================

// at the top of the file:

// #define SCAN_BLOCK_DIM   BLOCKSIZE  // needed by sharedMemExclusiveScan implementation
// #include "exclusiveScan.cu_inl"

// ...

// in a kernel:

// If you're using 2D indices, compute a linear thread index as folows.
// NOTE: scan assumes that every 32 adjacent linear thread indices 
// (0-31, 32-63, ...) form a warp, which means they execute in lockstep.

// If you do linearThreadIndex = threadIdx.x * blockDim.x + threadIdx.y;
// you will get a linear thread index, but it won't be sorted into warps,
// which will break scan!

// int linearThreadIndex =  threadIdx.y * blockDim.y + threadIdx.x;

// __shared__ uint prefixSumInput[BLOCKSIZE];
// __shared__ uint prefixSumOutput[BLOCKSIZE];
// __shared__ uint prefixSumScratch[2 * BLOCKSIZE];
// sharedMemExclusiveScan(linearThreadIndex, prefixSumInput, prefixSumOutput, prefixSumScratch, BLOCKSIZE);


#define LOG2_WARP_SIZE 5U
#define WARP_SIZE (1U << LOG2_WARP_SIZE)

//Almost the same as naive scan1Inclusive, but doesn't need __syncthreads()
//assuming size <= WARP_SIZE
inline __device__ void
warpScanInclusive(int threadIndex, float decay_data, float impulse_data,
    volatile float *sDecayScratch, volatile float *sImpulseScratch,
    float *resultDecay, float *resultImpulse, uint size){
    // Note some of the calculations are obscure because they are optimized.
    // For example, (threadIndex & (size - 1)) computes threadIndex % size,
    // which works, assuming size is a power of 2.

    uint pos = 2 * threadIndex - (threadIndex & (size - 1));
    sDecayScratch[pos] = 1.f;
    sImpulseScratch[pos] = 0.f;
    pos += size;
    sDecayScratch[pos] = decay_data;
    sImpulseScratch[pos] = impulse_data;

    for (uint offset = 1; offset < size; offset <<= 1) {
        // MAYBE: do if to subtract by 0 instead of using extra space
        sImpulseScratch[pos] = sDecayScratch[pos] * sImpulseScratch[pos - offset] + sImpulseScratch[pos];
        sDecayScratch[pos] *= sDecayScratch[pos - offset];
    }

    *resultDecay = sDecayScratch[pos];
    *resultImpulse = sImpulseScratch[pos];
}

__inline__ __device__ void
sharedMemRecurrentInclusiveScan(int threadIndex, float* sInputDecays, float* sInputImpulses,
    volatile float* sDecayScratch, volatile float* sImpulseScratch, uint size)
{
    if (size > WARP_SIZE) {

        float decay_data = sInputDecays[threadIndex];
        float impulse_data = sInputImpulses[threadIndex];

        //Bottom-level inclusive warp scan
        float warpResultDecay, warpResultImpulse;
        warpScanInclusive(threadIndex, decay_data, impulse_data,
            sDecayScratch, sImpulseScratch, &warpResultDecay, &warpResultImpulse,
            WARP_SIZE);

        // Save top elements of each warp for exclusive warp scan sync
        // to wait for warp scans to complete (because s_Data is being
        // overwritten)
        __syncthreads();

        if ( (threadIndex & (WARP_SIZE - 1)) == (WARP_SIZE - 1) ) {
            sDecayScratch[threadIndex >> LOG2_WARP_SIZE] = warpResultDecay;
            sImpulseScratch[threadIndex >> LOG2_WARP_SIZE] = warpImpulseDecay;
        }

        // wait for warp scans to complete
        __syncthreads();

        if ( threadIndex < (SCAN_BLOCK_DIM / WARP_SIZE)) {
            // grab top warp elements
            float decay_val = sDecayScratch[threadIndex];
            float impulse_val = sImpulseScratch[threadIndex];
            // calculate exclusive scan and write back to shared memory
            warpScanInclusive(threadIndex, decay_val, impulse_val,
                sDecayScratch, sImpulseScratch,
                &sDecayScratch[threadIndex + 1], &sImpulseScratch[threadIndex + 1], 
                size >> LOG2_WARP_SIZE);
        }

        //return updated warp scans with exclusive scan results
        __syncthreads();
        sInputImpulses[threadIndex] = (warpResultImpulse * sDecayScratch[threadIndex >> LOG2_WARP_SIZE]
            + sImpulseScratch[threadIndex >> LOG2_WARP_SIZE]);
        sInputDecays[threadIndex] = warpResultDecay * sDecayScratch[threadIndex >> LOG2_WARP_SIZE];

    } else if (threadIndex < WARP_SIZE) {
        float decay_data = sInputDecays[threadIndex];
        float impulse_data = sInputImpulses[threadIndex];
        sOutput[threadIndex] = warpScanInclusive(threadIndex, decay_data, impulse_data,
            sDecayScratch, sImpulseScratch,
            &sInputDecays[threadIndex], &sInputImpulses[threadIndex], size);
    }
}
